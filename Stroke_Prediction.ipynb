{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "67b2ee60-d380-4be6-81d2-c2c69d05eb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2f9686f6-4579-451a-b528-7874016571d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "df = pd.read_csv('healthcare-dataset-stroke-data.csv')\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e5354626-c9db-4531-963a-3ce0f5474995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and labels\n",
    "X = df.iloc[:, 1:-1].values\n",
    "y = df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "745ffd09-5549-4aa4-aabe-87fe7999a44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode categorical features\n",
    "ct = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('encoder', OneHotEncoder(drop='first'), [-1])\n",
    "    ], \n",
    "    remainder='passthrough'\n",
    ")\n",
    "X_transformed = ct.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "559c35d8-ac29-4426-8897-7fb833118ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numeric columns for scaling\n",
    "# Assuming the columns after one-hot encoding are all numeric\n",
    "numeric_columns_indices = [i for i in range(X_transformed.shape[1]) if np.issubdtype(X_transformed[:, i].dtype, np.number)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cc976953-91c2-4367-907a-436f78bf5d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No numeric columns found for scaling.\n"
     ]
    }
   ],
   "source": [
    "# Apply StandardScaler to numeric columns if any\n",
    "if numeric_columns_indices:\n",
    "    scaler = StandardScaler()\n",
    "    X_numeric = X_transformed[:, numeric_columns_indices]\n",
    "    X_numeric = scaler.fit_transform(X_numeric)\n",
    "\n",
    "    # Replace normalized numeric columns in transformed data\n",
    "    X_transformed[:, numeric_columns_indices] = X_numeric\n",
    "else:\n",
    "    print(\"No numeric columns found for scaling.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "28e4fcd3-9b85-4d0b-96a3-ab89d409f76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to float32\n",
    "X_transformed = np.asarray(X_transformed).astype('float32')\n",
    "y = np.asarray(y).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "44b93131-c81f-4ea7-8212-5118175136f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "49c24842-e878-478e-b443-c11dedc72aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dbd67780-bc3f-4369-aab9-bf1ce4318928",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2601e081-e821-487f-a3ba-5389e167081d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - accuracy: 0.8934 - loss: 1.6190 - val_accuracy: 0.9517 - val_loss: 0.6860\n",
      "Epoch 2/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338us/step - accuracy: 0.9158 - loss: 0.8097 - val_accuracy: 0.9517 - val_loss: 0.3120\n",
      "Epoch 3/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - accuracy: 0.9314 - loss: 0.4203 - val_accuracy: 0.9517 - val_loss: 0.2385\n",
      "Epoch 4/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.9351 - loss: 0.3534 - val_accuracy: 0.9517 - val_loss: 0.2204\n",
      "Epoch 5/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - accuracy: 0.9467 - loss: 0.2675 - val_accuracy: 0.9517 - val_loss: 0.2355\n",
      "Epoch 6/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - accuracy: 0.9592 - loss: 0.2005 - val_accuracy: 0.9517 - val_loss: 0.2273\n",
      "Epoch 7/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - accuracy: 0.9588 - loss: 0.2030 - val_accuracy: 0.9517 - val_loss: 0.2239\n",
      "Epoch 8/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - accuracy: 0.9631 - loss: 0.1756 - val_accuracy: 0.9517 - val_loss: 0.2307\n",
      "Epoch 9/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - accuracy: 0.9604 - loss: 0.1737 - val_accuracy: 0.9517 - val_loss: 0.2159\n",
      "Epoch 10/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.9580 - loss: 0.1898 - val_accuracy: 0.9517 - val_loss: 0.2030\n",
      "Epoch 11/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - accuracy: 0.9617 - loss: 0.1740 - val_accuracy: 0.9517 - val_loss: 0.2021\n",
      "Epoch 12/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - accuracy: 0.9620 - loss: 0.1704 - val_accuracy: 0.9517 - val_loss: 0.2119\n",
      "Epoch 13/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.9612 - loss: 0.1713 - val_accuracy: 0.9517 - val_loss: 0.2054\n",
      "Epoch 14/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - accuracy: 0.9594 - loss: 0.1648 - val_accuracy: 0.9517 - val_loss: 0.2113\n",
      "Epoch 15/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - accuracy: 0.9637 - loss: 0.1527 - val_accuracy: 0.9517 - val_loss: 0.2173\n",
      "Epoch 16/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - accuracy: 0.9573 - loss: 0.1711 - val_accuracy: 0.9517 - val_loss: 0.2180\n",
      "Epoch 17/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.9578 - loss: 0.1701 - val_accuracy: 0.9517 - val_loss: 0.1984\n",
      "Epoch 18/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - accuracy: 0.9622 - loss: 0.1630 - val_accuracy: 0.9517 - val_loss: 0.1996\n",
      "Epoch 19/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356us/step - accuracy: 0.9628 - loss: 0.1492 - val_accuracy: 0.9517 - val_loss: 0.2031\n",
      "Epoch 20/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - accuracy: 0.9575 - loss: 0.1652 - val_accuracy: 0.9517 - val_loss: 0.1968\n",
      "Epoch 21/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - accuracy: 0.9610 - loss: 0.1625 - val_accuracy: 0.9517 - val_loss: 0.2022\n",
      "Epoch 22/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359us/step - accuracy: 0.9602 - loss: 0.1518 - val_accuracy: 0.9517 - val_loss: 0.1955\n",
      "Epoch 23/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - accuracy: 0.9590 - loss: 0.1679 - val_accuracy: 0.9517 - val_loss: 0.2062\n",
      "Epoch 24/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - accuracy: 0.9618 - loss: 0.1594 - val_accuracy: 0.9517 - val_loss: 0.1949\n",
      "Epoch 25/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - accuracy: 0.9654 - loss: 0.1343 - val_accuracy: 0.9517 - val_loss: 0.1910\n",
      "Epoch 26/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - accuracy: 0.9644 - loss: 0.1394 - val_accuracy: 0.9517 - val_loss: 0.1962\n",
      "Epoch 27/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359us/step - accuracy: 0.9625 - loss: 0.1460 - val_accuracy: 0.9517 - val_loss: 0.1942\n",
      "Epoch 28/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.9599 - loss: 0.1493 - val_accuracy: 0.9517 - val_loss: 0.1914\n",
      "Epoch 29/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356us/step - accuracy: 0.9615 - loss: 0.1464 - val_accuracy: 0.9517 - val_loss: 0.1924\n",
      "Epoch 30/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359us/step - accuracy: 0.9639 - loss: 0.1419 - val_accuracy: 0.9517 - val_loss: 0.1908\n",
      "Epoch 31/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.9643 - loss: 0.1411 - val_accuracy: 0.9517 - val_loss: 0.1887\n",
      "Epoch 32/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348us/step - accuracy: 0.9637 - loss: 0.1386 - val_accuracy: 0.9517 - val_loss: 0.1894\n",
      "Epoch 33/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367us/step - accuracy: 0.9613 - loss: 0.1488 - val_accuracy: 0.9517 - val_loss: 0.1841\n",
      "Epoch 34/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346us/step - accuracy: 0.9660 - loss: 0.1348 - val_accuracy: 0.9517 - val_loss: 0.1870\n",
      "Epoch 35/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356us/step - accuracy: 0.9610 - loss: 0.1467 - val_accuracy: 0.9517 - val_loss: 0.1878\n",
      "Epoch 36/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - accuracy: 0.9682 - loss: 0.1258 - val_accuracy: 0.9517 - val_loss: 0.1864\n",
      "Epoch 37/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - accuracy: 0.9608 - loss: 0.1559 - val_accuracy: 0.9517 - val_loss: 0.1922\n",
      "Epoch 38/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346us/step - accuracy: 0.9560 - loss: 0.1593 - val_accuracy: 0.9517 - val_loss: 0.1898\n",
      "Epoch 39/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.9640 - loss: 0.1338 - val_accuracy: 0.9517 - val_loss: 0.1865\n",
      "Epoch 40/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345us/step - accuracy: 0.9599 - loss: 0.1572 - val_accuracy: 0.9517 - val_loss: 0.1879\n",
      "Epoch 41/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.9634 - loss: 0.1357 - val_accuracy: 0.9517 - val_loss: 0.1876\n",
      "Epoch 42/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - accuracy: 0.9588 - loss: 0.1543 - val_accuracy: 0.9517 - val_loss: 0.1824\n",
      "Epoch 43/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.9605 - loss: 0.1466 - val_accuracy: 0.9517 - val_loss: 0.1829\n",
      "Epoch 44/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - accuracy: 0.9637 - loss: 0.1367 - val_accuracy: 0.9517 - val_loss: 0.1825\n",
      "Epoch 45/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345us/step - accuracy: 0.9602 - loss: 0.1477 - val_accuracy: 0.9517 - val_loss: 0.1867\n",
      "Epoch 46/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - accuracy: 0.9569 - loss: 0.1512 - val_accuracy: 0.9517 - val_loss: 0.1843\n",
      "Epoch 47/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365us/step - accuracy: 0.9578 - loss: 0.1514 - val_accuracy: 0.9517 - val_loss: 0.1891\n",
      "Epoch 48/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - accuracy: 0.9563 - loss: 0.1508 - val_accuracy: 0.9517 - val_loss: 0.1868\n",
      "Epoch 49/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.9549 - loss: 0.1627 - val_accuracy: 0.9517 - val_loss: 0.1860\n",
      "Epoch 50/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - accuracy: 0.9676 - loss: 0.1207 - val_accuracy: 0.9517 - val_loss: 0.1851\n",
      "Epoch 51/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.9620 - loss: 0.1445 - val_accuracy: 0.9517 - val_loss: 0.1841\n",
      "Epoch 52/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363us/step - accuracy: 0.9574 - loss: 0.1541 - val_accuracy: 0.9517 - val_loss: 0.1870\n",
      "Epoch 53/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368us/step - accuracy: 0.9614 - loss: 0.1444 - val_accuracy: 0.9517 - val_loss: 0.1828\n",
      "Epoch 54/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.9621 - loss: 0.1365 - val_accuracy: 0.9517 - val_loss: 0.1836\n",
      "Epoch 55/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.9601 - loss: 0.1411 - val_accuracy: 0.9517 - val_loss: 0.1830\n",
      "Epoch 56/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - accuracy: 0.9561 - loss: 0.1600 - val_accuracy: 0.9517 - val_loss: 0.1890\n",
      "Epoch 57/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362us/step - accuracy: 0.9533 - loss: 0.1710 - val_accuracy: 0.9517 - val_loss: 0.1920\n",
      "Epoch 58/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366us/step - accuracy: 0.9676 - loss: 0.1279 - val_accuracy: 0.9517 - val_loss: 0.1841\n",
      "Epoch 59/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365us/step - accuracy: 0.9668 - loss: 0.1318 - val_accuracy: 0.9517 - val_loss: 0.1854\n",
      "Epoch 60/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - accuracy: 0.9654 - loss: 0.1325 - val_accuracy: 0.9517 - val_loss: 0.1900\n",
      "Epoch 61/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - accuracy: 0.9582 - loss: 0.1529 - val_accuracy: 0.9517 - val_loss: 0.1890\n",
      "Epoch 62/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - accuracy: 0.9610 - loss: 0.1395 - val_accuracy: 0.9517 - val_loss: 0.1884\n",
      "Epoch 63/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345us/step - accuracy: 0.9645 - loss: 0.1342 - val_accuracy: 0.9517 - val_loss: 0.1826\n",
      "Epoch 64/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - accuracy: 0.9689 - loss: 0.1263 - val_accuracy: 0.9517 - val_loss: 0.1860\n",
      "Epoch 65/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350us/step - accuracy: 0.9608 - loss: 0.1419 - val_accuracy: 0.9517 - val_loss: 0.1921\n",
      "Epoch 66/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.9616 - loss: 0.1461 - val_accuracy: 0.9517 - val_loss: 0.1898\n",
      "Epoch 67/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - accuracy: 0.9616 - loss: 0.1407 - val_accuracy: 0.9517 - val_loss: 0.1903\n",
      "Epoch 68/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - accuracy: 0.9627 - loss: 0.1392 - val_accuracy: 0.9517 - val_loss: 0.1898\n",
      "Epoch 69/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - accuracy: 0.9668 - loss: 0.1311 - val_accuracy: 0.9517 - val_loss: 0.1894\n",
      "Epoch 70/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - accuracy: 0.9605 - loss: 0.1391 - val_accuracy: 0.9517 - val_loss: 0.1876\n",
      "Epoch 71/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - accuracy: 0.9607 - loss: 0.1447 - val_accuracy: 0.9517 - val_loss: 0.1934\n",
      "Epoch 72/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - accuracy: 0.9627 - loss: 0.1401 - val_accuracy: 0.9517 - val_loss: 0.1853\n",
      "Epoch 73/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - accuracy: 0.9565 - loss: 0.1490 - val_accuracy: 0.9517 - val_loss: 0.1874\n",
      "Epoch 74/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - accuracy: 0.9617 - loss: 0.1457 - val_accuracy: 0.9517 - val_loss: 0.1941\n",
      "Epoch 75/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - accuracy: 0.9691 - loss: 0.1212 - val_accuracy: 0.9517 - val_loss: 0.1913\n",
      "Epoch 76/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357us/step - accuracy: 0.9599 - loss: 0.1474 - val_accuracy: 0.9517 - val_loss: 0.1907\n",
      "Epoch 77/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - accuracy: 0.9613 - loss: 0.1441 - val_accuracy: 0.9517 - val_loss: 0.1861\n",
      "Epoch 78/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - accuracy: 0.9638 - loss: 0.1331 - val_accuracy: 0.9517 - val_loss: 0.1961\n",
      "Epoch 79/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - accuracy: 0.9611 - loss: 0.1488 - val_accuracy: 0.9517 - val_loss: 0.1946\n",
      "Epoch 80/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - accuracy: 0.9683 - loss: 0.1259 - val_accuracy: 0.9517 - val_loss: 0.1913\n",
      "Epoch 81/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351us/step - accuracy: 0.9639 - loss: 0.1333 - val_accuracy: 0.9517 - val_loss: 0.1931\n",
      "Epoch 82/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.9595 - loss: 0.1497 - val_accuracy: 0.9517 - val_loss: 0.1884\n",
      "Epoch 83/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362us/step - accuracy: 0.9563 - loss: 0.1565 - val_accuracy: 0.9517 - val_loss: 0.1961\n",
      "Epoch 84/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360us/step - accuracy: 0.9591 - loss: 0.1480 - val_accuracy: 0.9517 - val_loss: 0.1870\n",
      "Epoch 85/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step - accuracy: 0.9606 - loss: 0.1429 - val_accuracy: 0.9517 - val_loss: 0.1916\n",
      "Epoch 86/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - accuracy: 0.9670 - loss: 0.1290 - val_accuracy: 0.9517 - val_loss: 0.1906\n",
      "Epoch 87/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.9578 - loss: 0.1475 - val_accuracy: 0.9517 - val_loss: 0.1943\n",
      "Epoch 88/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.9574 - loss: 0.1483 - val_accuracy: 0.9517 - val_loss: 0.1975\n",
      "Epoch 89/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - accuracy: 0.9580 - loss: 0.1500 - val_accuracy: 0.9517 - val_loss: 0.1894\n",
      "Epoch 90/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - accuracy: 0.9632 - loss: 0.1455 - val_accuracy: 0.9517 - val_loss: 0.1940\n",
      "Epoch 91/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - accuracy: 0.9637 - loss: 0.1335 - val_accuracy: 0.9517 - val_loss: 0.1945\n",
      "Epoch 92/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355us/step - accuracy: 0.9634 - loss: 0.1336 - val_accuracy: 0.9517 - val_loss: 0.1937\n",
      "Epoch 93/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - accuracy: 0.9616 - loss: 0.1338 - val_accuracy: 0.9517 - val_loss: 0.1918\n",
      "Epoch 94/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353us/step - accuracy: 0.9602 - loss: 0.1376 - val_accuracy: 0.9517 - val_loss: 0.1905\n",
      "Epoch 95/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - accuracy: 0.9586 - loss: 0.1522 - val_accuracy: 0.9517 - val_loss: 0.1989\n",
      "Epoch 96/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356us/step - accuracy: 0.9575 - loss: 0.1627 - val_accuracy: 0.9517 - val_loss: 0.1959\n",
      "Epoch 97/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356us/step - accuracy: 0.9629 - loss: 0.1357 - val_accuracy: 0.9517 - val_loss: 0.1904\n",
      "Epoch 98/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354us/step - accuracy: 0.9604 - loss: 0.1380 - val_accuracy: 0.9517 - val_loss: 0.1998\n",
      "Epoch 99/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347us/step - accuracy: 0.9547 - loss: 0.1554 - val_accuracy: 0.9517 - val_loss: 0.1996\n",
      "Epoch 100/100\n",
      "\u001b[1m111/111\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352us/step - accuracy: 0.9600 - loss: 0.1439 - val_accuracy: 0.9517 - val_loss: 0.1981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2a474d070>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "be749ae7-a47c-4386-a571-6fb86e836192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 612us/step\n",
      "Accuracy: 0.9460285132382892\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5).astype('float32')  # Convert probabilities to binary outcomes\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a046b255-5a3e-4ef0-8e6c-0717e64ce340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input for prediction\n",
    "def preprocess_input(input_features):\n",
    "    # Convert input to a DataFrame\n",
    "    input_df = pd.DataFrame([input_features], columns=df.columns[1:-1])\n",
    "    \n",
    "    # Apply the same preprocessing steps\n",
    "    input_transformed = ct.transform(input_df)\n",
    "    \n",
    "    # Normalize if numeric columns exist in the transformed input\n",
    "    input_numeric = input_transformed[:, numeric_columns_indices] if numeric_columns_indices else np.array([])\n",
    "    if input_numeric.size > 0:\n",
    "        input_numeric = scaler.transform(input_numeric)\n",
    "        input_transformed[:, numeric_columns_indices] = input_numeric\n",
    "    \n",
    "    return input_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "18a73d05-1650-4560-9d65-f8f8ac82ab4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example input\n",
    "example_input = [0, 0, 1, 0, 40, 1, 1, 1, 0, 0, 170, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26ba3e5-3a3c-4ae4-822a-96165fb8cfe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
